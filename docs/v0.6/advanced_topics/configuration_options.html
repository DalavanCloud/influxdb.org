<!DOCTYPE html><html><head><meta charset="utf-8" /><!--Always force latest IE rendering engine or request Chrome Frame--><meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" /><!--Use title if it's in the page YAML frontmatter--><title>InfluxDB Documentation</title><link href="/stylesheets/all.css" media="screen" rel="stylesheet" type="text/css" /><script src="/javascripts/all.js" type="text/javascript"></script></head><body class="docs docs_v0"><section class="nav"><div class="row"><nav class="top-bar hide-for-small"><ul class="title-area"><li class="name"><a href="/"><img src="/images/influxdb-light-24px.png" /></a></li></ul><li class="toggle-topbar menu-icon"><a href="#"><span>Menu</span></a></li><section class="top-bar-section"><ul class="right"><li class="divider"></li><li><a href="/docs/v0.6/introduction/overview.html">Overview</a></li><li class="divider"></li><li><a href="https://customers.influxdb.com">Support & Hosting</a></li><li class="divider"></li><li><a href="/blog">Blog</a></li><li class="divider"></li><li><a href="/docs/v0.6/introduction/getting_started.html">Docs</a></li><li class="divider"></li><li><a href="/community">Community</a></li><li class="divider"></li><li><a target="_" href="http://play.influxdb.org">Play</a></li><li class="divider"></li><li class="has-form"><a class="button" href="/download">Download</a></li></ul></section></nav></div></section><section role="main"><div class="row"><div class="large-4 medium-4 columns"><div class="sidebar"><nav><ul class="side-nav"><li class="heading">Introduction</li><li><a href="/docs/v0.6/introduction/overview.html">Overview</a></li><li><a href="/docs/v0.6/introduction/installation.html">Installation</a></li><li><a href="/docs/v0.6/introduction/getting_started.html">Getting Started</a></li><li class="divider"></li><li class="heading">API</li><li><a href="/docs/v0.6/api/reading_and_writing_data.html">Reading & Writing Data</a></li><li><a href="/docs/v0.6/api/query_language.html">Query Language</a></li><li><a href="/docs/v0.6/api/aggregate_functions.html">Aggregate Functions</a></li><li><a href="/docs/v0.6/api/continuous_queries.html">Continuous Queries</a></li><li><a href="/docs/v0.6/api/chunked_responses.html">Chunked HTTP Responses</a></li><li><a href="/docs/v0.6/api/administration.html">Administration</a></li><li class="divider"></li><li class="heading">UI</li><li><a href="/docs/v0.6/ui/built_in_admin_and_explorer.html">Built-in Admin and Explorer Interface</a></li><li><a href="/docs/v0.6/ui/grafana.html">Grafana Dashboards</a></li><li><a href="https://github.com/hakobera/influga">Influga Dashboards</a></li><li class="divider"></li><li class="heading">Advanced Topics</li><li><a href="/docs/v0.6/advanced_topics/sharding_and_storage.html">Underlying Storage and Shards</a></li><li><a href="/docs/v0.6/advanced_topics/configuration_options.html">Configuration Options</a></li><li><a href="/docs/v0.6/advanced_topics/schema_design.html">Schema Design</a></li><li><a href="/docs/v0.6/advanced_topics/performance_considerations.html">Performance Considerations</a></li><li><a href="/docs/v0.6/advanced_topics/security.html">Security</a></li><li class="divider"></li><li class="heading">Clustering</li><li><a href="/docs/v0.6/clustering/design.html">Design</a></li><li><a href="/docs/v0.6/clustering/setup.html">Setup</a></li><li class="divider"></li><li class="heading">Future Features</li><li><a href="/docs/v0.6/future/binary_protocol.html">Binary Protocol</a></li><li><a href="/docs/v0.6/future/pubsub.html">Pubsub</a></li><li><a href="/docs/v0.6/future/column_indexes.html">Column Indexes and Tags</a></li><li><a href="/docs/v0.6/future/shard_spaces.html">Shard Spaces and Retention Policies</a></li><li><a href="/docs/v0.6/future/custom_functions.html">Custom Functions</a></li><li><a href="/docs/v0.6/future/security.html">Security Enhancements</a></li><li class="divider"></li><li class="heading">Client Libraries</li><li><a href="/docs/v0.6/client_libraries/javascript.html">JavaScript</a></li><li><a href="https://github.com/influxdb/influxdb-ruby">Ruby</a></li><li><a href="https://github.com/influxdb/influxdb-rails">Rails</a></li><li><a href="/docs/v0.6/client_libraries/python.html">Python</a></li><li><a href="/docs/v0.6/client_libraries/node.html">Node.js</a></li><li><a href="/docs/v0.6/client_libraries/php.html">PHP</a></li><li><a href="https://github.com/majst01/influxdb-java">Java</a></li><li><a href="https://github.com/olauzon/capacitor">Clojure</a></li><li><a href="https://github.com/mmaul/cl-influxdb">Common Lisp</a></li><li><a href="https://github.com/novaquark/metrics-influxdb">Java Metrics</a></li><li><a href="https://github.com/influxdb/influxdb-go">Go</a></li><li><a href="https://github.com/rcrowley/go-metrics">Go Metrics</a></li><li><a href="https://github.com/influxdb/influxdb-scala">Scala</a></li><li><a href="https://github.com/influxdb/influxdb-r">R</a></li><li><a href="https://metacpan.org/pod/InfluxDB">Perl</a></li><li><a href="https://github.com/maoe/influxdb-haskell">Haskell</a></li><li class="divider"></li><li class="heading">Contributing</li><li><a href="/community/cla.html">CLA</a></li><li><a href="https://github.com/influxdb/influxdb.org">To this Documentation</a></li><li><a href="https://github.com/influxdb/influxdb/blob/master/LICENSE">License (MIT)</a></li><li><a href="/docs/v0.6/contributing/building.html">Building From Source</a></li><li class="divider"></li><li class="heading">Other Libraries and Tools</li><li><a href="https://github.com/FGRibreau/influxdb-cli">CLI (Node)</a></li><li><a href="https://github.com/FGRibreau/influxdb-cli">CLI (Node)</a></li><li><a href="http://grafana.org/">Grafana (dashboards)</a></li><li><a href="https://github.com/obfuscurity/tasseo">Tasseo (realtime dashboard)</a></li><li><a href="https://github.com/bernd/statsd-influxdb-backend">StatsD Backend</a></li><li><a href="https://github.com/bpaquet/collectd-influxdb-proxy">CollectD Proxy</a></li><li><a href="https://github.com/fangli/fluent-plugin-influxdb">FluentD Plugin</a></li><li><a href="https://github.com/lusis/sensu_influxdb_handler">Sensu Handler</a></li><li><a href="https://github.com/SimpleFinance/chef-handler-influxdb">Chef Handler/Reporter</a></li><li><a href="https://github.com/CargoSense/puppet-influxdb">Config Management via Boxen</a></li><li class="divider"></li><li class="heading">Docs Versions</li><li><a href="/docs/v0.6/introduction/overview.html">v0.6</a></li></ul></nav><a class="button download expand" href="/download" style="margin-bottom: 0;">Download InfluxDB</a></div></div><div class="large-8 medium-8 columns"><h1 id="toc_0">Configuration</h1>

<p>Here&rsquo;s a sample configuration file. Comments in the file explain the options.</p>
<pre class="highlight toml"><span class="c"># Welcome to the InfluxDB configuration file.</span>

<span class="c"># If hostname (on the OS) doesn&#39;t return a name that can be resolved by the other</span>
<span class="c"># systems in the cluster, you&#39;ll have to set the hostname to an IP or something</span>
<span class="c"># that can be resolved here.</span>
<span class="c"># hostname = &quot;&quot;</span>

<span class="py">bind-address</span> <span class="p">=</span> <span class="s">&quot;0.0.0.0&quot;</span>

<span class="nn">[logging]</span>
<span class="c"># logging level can be one of &quot;debug&quot;, &quot;info&quot;, &quot;warn&quot; or &quot;error&quot;</span>
<span class="py">level</span>  <span class="p">=</span> <span class="s">&quot;info&quot;</span>
<span class="py">file</span>   <span class="p">=</span> <span class="s">&quot;influxdb.log&quot;</span>         <span class="c"># stdout to log to standard out</span>

<span class="c"># Configure the admin server</span>
<span class="nn">[admin]</span>
<span class="py">port</span>   <span class="p">=</span> <span class="mi">8083</span>              <span class="c"># binding is disabled if the port isn&#39;t set</span>
<span class="py">assets</span> <span class="p">=</span> <span class="s">&quot;./admin&quot;</span>

<span class="c"># Configure the http api</span>
<span class="nn">[api]</span>
<span class="py">port</span>     <span class="p">=</span> <span class="mi">8086</span>    <span class="c"># binding is disabled if the port isn&#39;t set</span>
<span class="c"># ssl-port = 8084    # Ssl support is enabled if you set a port and cert</span>
<span class="c"># ssl-cert = /path/to/cert.pem</span>

<span class="c"># connections will timeout after this amount of time. Ensures that clients that misbehave </span>
<span class="c"># and keep alive connections they don&#39;t use won&#39;t end up connection a million times.</span>
<span class="c"># However, if a request is taking longer than this to complete, could be a problem.</span>
<span class="py">read-timeout</span> <span class="p">=</span> <span class="s">&quot;5s&quot;</span>

<span class="nn">[input_plugins]</span>

  <span class="c"># Configure the graphite api</span>
  <span class="nn">[input_plugins.graphite]</span>
  <span class="py">enabled</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="c"># port = 2003</span>
  <span class="c"># database = &quot;&quot;  # store graphite data in this database</span>

<span class="c"># Raft configuration</span>
<span class="nn">[raft]</span>
<span class="c"># The raft port should be open between all servers in a cluster.</span>
<span class="c"># However, this port shouldn&#39;t be accessible from the internet.</span>

<span class="py">port</span> <span class="p">=</span> <span class="mi">8090</span>

<span class="c"># Where the raft logs are stored. The user running InfluxDB will need read/write access.</span>
<span class="py">dir</span>  <span class="p">=</span> <span class="s">&quot;/tmp/influxdb/development/raft&quot;</span>

<span class="c"># election-timeout = &quot;1s&quot;</span>

<span class="nn">[storage]</span>
<span class="py">dir</span> <span class="p">=</span> <span class="s">&quot;/tmp/influxdb/development/db&quot;</span>
<span class="c"># How many requests to potentially buffer in memory. If the buffer gets filled then writes</span>
<span class="c"># will still be logged and once the local storage has caught up (or compacted) the writes</span>
<span class="c"># will be replayed from the WAL</span>
<span class="py">write-buffer-size</span> <span class="p">=</span> <span class="mi">10000</span>

<span class="nn">[cluster]</span>
<span class="c"># A comma separated list of servers to seed</span>
<span class="c"># this server. this is only relevant when the</span>
<span class="c"># server is joining a new cluster. Otherwise</span>
<span class="c"># the server will use the list of known servers</span>
<span class="c"># prior to shutting down. Any server can be pointed to</span>
<span class="c"># as a seed. It will find the Raft leader automatically.</span>

<span class="c"># Here&#39;s an example. Note that the port on the host is the same as the raft port.</span>
<span class="c"># seed-servers = [&quot;hosta:8090&quot;,&quot;hostb:8090&quot;]</span>

<span class="c"># Replication happens over a TCP connection with a Protobuf protocol.</span>
<span class="c"># This port should be reachable between all servers in a cluster.</span>
<span class="c"># However, this port shouldn&#39;t be accessible from the internet.</span>

<span class="py">protobuf_port</span> <span class="p">=</span> <span class="mi">8099</span>
<span class="py">protobuf_timeout</span> <span class="p">=</span> <span class="s">&quot;2s&quot;</span> <span class="c"># the write timeout on the protobuf conn any duration parseable by time.ParseDuration</span>
<span class="py">protobuf_heartbeat</span> <span class="p">=</span> <span class="s">&quot;200ms&quot;</span> <span class="c"># the heartbeat interval between the servers. must be parseable by time.ParseDuration</span>
<span class="py">protobuf_min_backoff</span> <span class="p">=</span> <span class="s">&quot;1s&quot;</span> <span class="c"># the minimum backoff after a failed heartbeat attempt</span>
<span class="py">protobuf_max_backoff</span> <span class="p">=</span> <span class="s">&quot;10s&quot;</span> <span class="c"># the maxmimum backoff after a failed heartbeat attempt</span>

<span class="c"># How many write requests to potentially buffer in memory per server. If the buffer gets filled then writes</span>
<span class="c"># will still be logged and once the server has caught up (or come back online) the writes</span>
<span class="c"># will be replayed from the WAL</span>
<span class="py">write-buffer-size</span> <span class="p">=</span> <span class="mi">10000</span>

<span class="c"># the maximum number of responses to buffer from remote nodes, if the</span>
<span class="c"># expected number of responses exceed this number then querying will</span>
<span class="c"># happen sequentially and the buffer size will be limited to this</span>
<span class="c"># number</span>
<span class="py">max-response-buffer-size</span> <span class="p">=</span> <span class="mi">100000</span>

<span class="c"># When queries get distributed out to shards, they go in parallel. This means that results can get buffered</span>
<span class="c"># in memory since results will come in any order, but have to be processed in the correct time order.</span>
<span class="c"># Setting this higher will give better performance, but you&#39;ll need more memory. Setting this to 1 will ensure</span>
<span class="c"># that you don&#39;t need to buffer in memory, but you won&#39;t get the best performance.</span>
<span class="py">concurrent-shard-query-limit</span> <span class="p">=</span> <span class="mi">10</span>

<span class="nn">[leveldb]</span>

<span class="c"># Maximum mmap open files, this will affect the virtual memory used by</span>
<span class="c"># the process</span>
<span class="py">max-open-files</span> <span class="p">=</span> <span class="mi">40</span>

<span class="c"># LRU cache size, LRU is used by leveldb to store contents of the</span>
<span class="c"># uncompressed sstables. You can use `m` or `g` prefix for megabytes</span>
<span class="c"># and gigabytes, respectively.</span>
<span class="py">lru-cache-size</span> <span class="p">=</span> <span class="s">&quot;200m&quot;</span>

<span class="c"># The default setting on this is 0, which means unlimited. Set this to something if you want to</span>
<span class="c"># limit the max number of open files. max-open-files is per shard so this * that will be max.</span>
<span class="py">max-open-shards</span> <span class="p">=</span> <span class="mi">0</span>

<span class="c"># The default setting is 100. This option tells how many points will be fetched from LevelDb before</span>
<span class="c"># they get flushed into backend.</span>
<span class="py">point-batch-size</span> <span class="p">=</span> <span class="mi">100</span>

<span class="c"># These options specify how data is sharded across the cluster. There are two</span>
<span class="c"># shard configurations that have the same knobs: short term and long term.</span>
<span class="c"># Any series that begins with a capital letter like Exceptions will be written</span>
<span class="c"># into the long term storage. Any series beginning with a lower case letter</span>
<span class="c"># like exceptions will be written into short term. The idea being that you</span>
<span class="c"># can write high precision data into short term and drop it after a couple</span>
<span class="c"># of days. Meanwhile, continuous queries can run downsampling on the short term</span>
<span class="c"># data and write into the long term area.</span>
<span class="nn">[sharding]</span>
  <span class="c"># how many servers in the cluster should have a copy of each shard.</span>
  <span class="c"># this will give you high availability and scalability on queries</span>
  <span class="py">replication-factor</span> <span class="p">=</span> <span class="mi">1</span>

  <span class="nn">[sharding.short-term]</span>
  <span class="c"># each shard will have this period of time. Note that it&#39;s best to have</span>
  <span class="c"># group by time() intervals on all queries be &lt; than this setting. If they are</span>
  <span class="c"># then the aggregate is calculated locally. Otherwise, all that data gets sent</span>
  <span class="c"># over the network when doing a query.</span>
  <span class="py">duration</span> <span class="p">=</span> <span class="s">&quot;7d&quot;</span>

  <span class="c"># split will determine how many shards to split each duration into. For example,</span>
  <span class="c"># if we created a shard for 2014-02-10 and split was set to 2. Then two shards</span>
  <span class="c"># would be created that have the data for 2014-02-10. By default, data will</span>
  <span class="c"># be split into those two shards deterministically by hashing the (database, serise)</span>
  <span class="c"># tuple. That means that data for a given series will be written to a single shard</span>
  <span class="c"># making querying efficient. That can be overridden with the next option.</span>
  <span class="py">split</span> <span class="p">=</span> <span class="mi">1</span>

  <span class="c"># You can override the split behavior to have the data for series that match a</span>
  <span class="c"># given regex be randomly distributed across the shards for a given interval.</span>
  <span class="c"># You can use this if you have a hot spot for a given time series writing more</span>
  <span class="c"># data than a single server can handle. Most people won&#39;t have to resort to this</span>
  <span class="c"># option. Also note that using this option means that queries will have to send</span>
  <span class="c"># all data over the network so they won&#39;t be as efficient.</span>
  <span class="c"># split-random = &quot;/^hf.*/&quot;</span>

  <span class="nn">[sharding.long-term]</span>
  <span class="py">duration</span> <span class="p">=</span> <span class="s">&quot;30d&quot;</span>
  <span class="py">split</span> <span class="p">=</span> <span class="mi">1</span>
  <span class="c"># split-random = &quot;/^Hf.*/&quot;</span>

<span class="nn">[wal]</span>

<span class="py">dir</span>   <span class="p">=</span> <span class="s">&quot;/tmp/influxdb/development/wal&quot;</span>
<span class="py">flush-after</span> <span class="p">=</span> <span class="mi">1000</span> <span class="c"># the number of writes after which wal will be flushed, 0 for flushing on every write</span>
<span class="py">bookmark-after</span> <span class="p">=</span> <span class="mi">1000</span> <span class="c"># the number of writes after which a bookmark will be created</span>

<span class="c"># the number of writes after which an index entry is created pointing</span>
<span class="c"># to the offset of the first request, default to 1k</span>
<span class="py">index-after</span> <span class="p">=</span> <span class="mi">1000</span>

<span class="c"># the number of requests per one log file, if new requests came in a</span>
<span class="c"># new log file will be created</span>
<span class="py">requests-per-logfile</span> <span class="p">=</span> <span class="mi">10000</span>
</pre></div></div></section><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-45024174-1', 'influxdb.org');
ga('send', 'pageview');</script><script type="text/javascript">$("h1,h2,h3,h4").each(function(i, el) {
    id = el.id;
    if (id.match("^toc_.*")) {
        text = $(el).text();
        $(el).html('<a href="#' + id + '">' + text + '</a>');
    }
});</script></body></html>